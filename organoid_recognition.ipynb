{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "organoid_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f235cbed205d4db1a69c582da2039ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "state": {
            "_options_labels": [
              "Matrigel coated plate 2",
              "FDA screen 113 FDA1 n1 test",
              "Test quality pictures",
              "95 plate1 FDA1 n1",
              "95 plate2 FDA2 n1",
              "95 plate4 FDA2 n2",
              "79 plate1 FDA1 n1",
              "79-plate2-FDA2-n1",
              "113-plate2-FDA1-n2",
              "188-plate2-FDA1-n2",
              "188-plate4-FDA2-n2",
              "95 plate3 FDA1 n2",
              "188-plate5-FDA2-n3 ",
              "188-plate1-FDA1-n1 all",
              "113-plate1-FDA1-n1",
              "113-plate5-FDA2-n3",
              "113-plate6-FDA1-n3",
              "188-plate3-FDA2-n1",
              "113-plate3-FDA2-n1",
              "188-plate6-FDA1-n3",
              "188-plate1-FDA1-n1",
              "113-plate4-FDA2-n2",
              "20200108 LR011C Charac TMEM16A KO",
              "20200109 LR-005E inside out 2x CF",
              "Livia-96W-79-plate1",
              "Livia-96W-79-plate2",
              "Livia-96W-79-plate3",
              "Livia-96W-188-plate2",
              "Livia-96W-95-plate1",
              "Livia-96W-95-plate2",
              "Livia-96W-95-plate3",
              "Livia-96W-113-plate1",
              "Livia-96W-113-plate2",
              "Livia96W-113-plate3",
              "Livia-96W-188-plate1",
              "Livia-96W-188-plate3",
              "Livia-graphs",
              "LR-009F inside out plate 1",
              "LR-009F inside out plate 2",
              "standardization_test"
            ],
            "_view_name": "DropdownView",
            "style": "IPY_MODEL_a87fcdb8139d4f5484e78647ae1a904d",
            "_dom_classes": [],
            "description": "Directory:",
            "_model_name": "DropdownModel",
            "index": 0,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da6003430d6040fba29df958f557a414"
          }
        },
        "a87fcdb8139d4f5484e78647ae1a904d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da6003430d6040fba29df958f557a414": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "029e89ccf48a40cb894cb75daf5d9249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "state": {
            "_view_name": "IntSliderView",
            "style": "IPY_MODEL_fa48d5277d0d494fb7bac315aadf3d22",
            "_dom_classes": [],
            "description": "Min Side:",
            "step": 100,
            "_model_name": "IntSliderModel",
            "orientation": "horizontal",
            "max": 2000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1800,
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "min": 800,
            "continuous_update": true,
            "readout_format": "d",
            "description_tooltip": "Larger \"Image Size\" allows you to detect smaller orgaoids at the cost of computational demand.",
            "readout": true,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a35bb7fd9a54b1a8a77321f928c0159"
          }
        },
        "fa48d5277d0d494fb7bac315aadf3d22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "state": {
            "_view_name": "StyleView",
            "handle_color": null,
            "_model_name": "SliderStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a35bb7fd9a54b1a8a77321f928c0159": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "22ac21b556394cbaba7f26128d7d9fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatSliderModel",
          "state": {
            "_view_name": "FloatSliderView",
            "style": "IPY_MODEL_8ef9172faa8f464c9c180cba8d57b8d4",
            "_dom_classes": [],
            "description": "Contrast",
            "step": 0.25,
            "_model_name": "FloatSliderModel",
            "orientation": "horizontal",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "min": 1,
            "continuous_update": true,
            "readout_format": ".2f",
            "description_tooltip": "Larger \"Contrast\" can improve detection sometimes.",
            "readout": true,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b70a3c72aba24956aee0e01bd417dbfb"
          }
        },
        "8ef9172faa8f464c9c180cba8d57b8d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "state": {
            "_view_name": "StyleView",
            "handle_color": null,
            "_model_name": "SliderStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b70a3c72aba24956aee0e01bd417dbfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8e17bd8f7dd48bdaa257e77cb342f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatSliderModel",
          "state": {
            "_view_name": "FloatSliderView",
            "style": "IPY_MODEL_08ff4ed29f2d4c1ba4cab5a9b8b85b50",
            "_dom_classes": [],
            "description": "Threshold",
            "step": 0.05,
            "_model_name": "FloatSliderModel",
            "orientation": "horizontal",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0.9,
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "min": 0,
            "continuous_update": true,
            "readout_format": ".2f",
            "description_tooltip": "Use larger \"Threshold\" to eliminate false positives.",
            "readout": true,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_35c6fa56e75149b88b7744d82504bbac"
          }
        },
        "08ff4ed29f2d4c1ba4cab5a9b8b85b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "state": {
            "_view_name": "StyleView",
            "handle_color": null,
            "_model_name": "SliderStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "35c6fa56e75149b88b7744d82504bbac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a60131bbce44d92b85ee5e6b33b5feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "state": {
            "_view_name": "IntSliderView",
            "style": "IPY_MODEL_6e1578f82cd7413c98557864f9005f59",
            "_dom_classes": [],
            "description": "Seed",
            "step": 1,
            "_model_name": "IntSliderModel",
            "orientation": "horizontal",
            "max": 40,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "min": 1,
            "continuous_update": true,
            "readout_format": "d",
            "description_tooltip": "Change value if parameter optimization should be performed on another image",
            "readout": true,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7722449f11b049ffa299ff0b4e737c83"
          }
        },
        "6e1578f82cd7413c98557864f9005f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "state": {
            "_view_name": "StyleView",
            "handle_color": null,
            "_model_name": "SliderStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7722449f11b049ffa299ff0b4e737c83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViGZv9mIQulP",
        "colab_type": "text"
      },
      "source": [
        "# Organoid quantification\n",
        "\n",
        "This notebook detects and quantifies organoid size. It uses the model trained for [OrgaQuant](https://github.com/TKassis/OrgaQuant). The notebook contains several steps:\n",
        "\n",
        "1. Mounting the Google Drive to access data\n",
        "2. Installing and loading dependencies \n",
        "3. Setting parameters for organoid detection\n",
        "4. Batch quantify all images in the folder\n",
        "\n",
        "Google Drive instructions\n",
        "- Ensure that the shared `OrgaSwell` directory is placed in the Google Drive root\n",
        "- Ensure that images to be quantified are placed within a subdirectory in `OrgaSwell/images`\n",
        "\n",
        "## 1. Mount the Google Drive to access data\n",
        "\n",
        "Follow the link and instructions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e4uZutmtiDW",
        "colab_type": "code",
        "outputId": "ccb5fe7e-9f44-49de-ee46-709ea30aaed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW58uXG7mXDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !git clone https://github.com/TKassis/OrgaQuant.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIeco7BwQ_RW",
        "colab_type": "text"
      },
      "source": [
        "## 2. Install and load dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOLQzM6etDGE",
        "colab_type": "code",
        "outputId": "59ed2524-5871-4cc5-8534-62a685d4030c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "%cd drive/My\\ Drive/OrgaSwell/OrgaQuant\n",
        "\n",
        "# Building keras-resnet\n",
        "!pip install -q keras-resnet==0.2.0 # cython keras matplotlib opencv-python\n",
        "!python setup.py build_ext --inplace -q\n",
        "%cd ..\n",
        "\n",
        "# Supress tensorflow warnings\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from google.colab.patches import cv2_imshow\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from OrgaQuant.keras_retinanet import models\n",
        "from OrgaQuant.keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image, adjust_contrast\n",
        "from OrgaQuant.keras_retinanet.utils.visualization import draw_box\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "def load_orga_model():\n",
        "  model = models.load_model(\"OrgaQuant/trained_models/orgaquant_intestinal_v2.h5\", backbone_name='resnet50')\n",
        "  return model\n",
        "\n",
        "model = load_orga_model()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/My Drive/OrgaSwell/OrgaQuant'\n",
            "/content/drive/My Drive/OrgaSwell\n",
            "python3: can't open file 'setup.py': [Errno 2] No such file or directory\n",
            "/content/drive/My Drive\n",
            "tracking <tf.Variable 'Variable_5:0' shape=(9, 4) dtype=float32> anchors\n",
            "tracking <tf.Variable 'Variable_6:0' shape=(9, 4) dtype=float32> anchors\n",
            "tracking <tf.Variable 'Variable_7:0' shape=(9, 4) dtype=float32> anchors\n",
            "tracking <tf.Variable 'Variable_8:0' shape=(9, 4) dtype=float32> anchors\n",
            "tracking <tf.Variable 'Variable_9:0' shape=(9, 4) dtype=float32> anchors\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JTA9BbGRU-Q",
        "colab_type": "text"
      },
      "source": [
        "## 3. Setting parameters for organoid detection\n",
        "\n",
        "Adjust the sliders and assess image generated by the next cell. If output is not as required, change settings and try again. Initial values are manually optimized to minimize false positives\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo8M8iqnQsR_",
        "colab_type": "code",
        "outputId": "93c83cdd-5047-4237-b3bf-d7ef2a5611ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169,
          "referenced_widgets": [
            "f235cbed205d4db1a69c582da2039ae1",
            "a87fcdb8139d4f5484e78647ae1a904d",
            "da6003430d6040fba29df958f557a414",
            "029e89ccf48a40cb894cb75daf5d9249",
            "fa48d5277d0d494fb7bac315aadf3d22",
            "7a35bb7fd9a54b1a8a77321f928c0159",
            "22ac21b556394cbaba7f26128d7d9fb9",
            "8ef9172faa8f464c9c180cba8d57b8d4",
            "b70a3c72aba24956aee0e01bd417dbfb",
            "b8e17bd8f7dd48bdaa257e77cb342f6e",
            "08ff4ed29f2d4c1ba4cab5a9b8b85b50",
            "35c6fa56e75149b88b7744d82504bbac",
            "3a60131bbce44d92b85ee5e6b33b5feb",
            "6e1578f82cd7413c98557864f9005f59",
            "7722449f11b049ffa299ff0b4e737c83"
          ]
        }
      },
      "source": [
        "slider_min_side = widgets.IntSlider(value=1800, min=800, max=2000, step=100, description='Min Side:',\n",
        "                                    description_tooltip='Larger \"Image Size\" allows you to detect smaller orgaoids at the cost of computational demand.')\n",
        "slider_contrast = widgets.FloatSlider(value=2, min=1, max=3, step=0.25, description='Contrast', \n",
        "                                      description_tooltip='Larger \"Contrast\" can improve detection sometimes.')\n",
        "slider_threshold  = widgets.FloatSlider(value=0.9, min=0, max=1, step=0.05, description='Threshold', \n",
        "                                        description_tooltip='Use larger \"Threshold\" to eliminate false positives.')\n",
        "slider_seed = widgets.IntSlider(value=1, min=1, max=40, step=1, description='Seed',\n",
        "                                    description_tooltip='Change value if parameter optimization should be performed on another image')\n",
        "\n",
        "dropdown_path = widgets.Dropdown(options=[x.name for x in Path('./images').iterdir() if x.is_dir()], description='Directory:',disabled=False)\n",
        "\n",
        "display(dropdown_path, slider_min_side, slider_contrast, slider_threshold, slider_seed)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f235cbed205d4db1a69c582da2039ae1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Dropdown(description='Directory:', options=('Matrigel coated plate 2', 'FDA screen 113 FDA1 n1 test', 'Test qu…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "029e89ccf48a40cb894cb75daf5d9249",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "IntSlider(value=1800, description='Min Side:', description_tooltip='Larger \"Image Size\" allows you to detect s…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22ac21b556394cbaba7f26128d7d9fb9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "FloatSlider(value=2.0, description='Contrast', description_tooltip='Larger \"Contrast\" can improve detection so…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8e17bd8f7dd48bdaa257e77cb342f6e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "FloatSlider(value=0.9, description='Threshold', description_tooltip='Use larger \"Threshold\" to eliminate false…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a60131bbce44d92b85ee5e6b33b5feb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "IntSlider(value=1, description='Seed', description_tooltip='Change value if parameter optimization should be p…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGGSjikIzlxj",
        "colab_type": "code",
        "outputId": "d2ec939e-07d3-4d92-d3fd-85af28b51281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "min_side = slider_min_side.value\n",
        "contrast = slider_contrast.value\n",
        "threshold = slider_threshold.value\n",
        "seed = slider_seed.value\n",
        "folder_path = Path('./images') / dropdown_path.value\n",
        "\n",
        "# Recreate imagelist in case cells are run interactive\n",
        "exclude_strings = ['_detected', '_processed']\n",
        "imagelist = [i for i in Path(folder_path).glob('**/*.jpg') if not any(x in str(i) for x in exclude_strings)]\n",
        "\n",
        "print(f'Images to analyze in {folder_path}: {len(imagelist)}')\n",
        "\n",
        "np.random.seed(seed)\n",
        "image_path = np.random.choice(imagelist, size=1)[0]\n",
        "# load image\n",
        "image = read_image_bgr(image_path)\n",
        "\n",
        "# copy to draw on\n",
        "draw = image.copy()\n",
        "draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# preprocess image for network\n",
        "image = adjust_contrast(image,contrast)\n",
        "image = preprocess_image(image)\n",
        "image, scale = resize_image(image, min_side=min_side, max_side=2048)\n",
        "\n",
        "# process image\n",
        "boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
        "\n",
        "# correct for image scale\n",
        "boxes /= scale\n",
        "\n",
        "num_org = 0\n",
        "# visualize detections\n",
        "for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
        "    # scores are sorted so we can break\n",
        "    if score < threshold:\n",
        "        break\n",
        "    num_org= num_org + 1\n",
        "    b = box.astype(int)\n",
        "    draw_box(draw, b, color=(255, 0, 255))\n",
        "\n",
        "print(f'{num_org} particles were detected in {image_path}')\n",
        "\n",
        "num_org, cv2_imshow(draw)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Images to analyze in images/Matrigel coated plate 2: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-982b05681741>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagelist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m# load image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_image_bgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 'a' cannot be empty unless no samples are taken"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeUMv40TSEeE",
        "colab_type": "text"
      },
      "source": [
        "## 4. Batch quantify all images in the folder\n",
        "\n",
        "This will take a while depending on the number of images and the value set for min side. \n",
        "\n",
        "For each image, an csv and jpg are created in the same directory. The CSV contains the quantification for the image, and the jpg contains annotation of the detected organoids\n",
        "\n",
        "### Quantitative output\n",
        "2 files will be created in the parent directory:\n",
        "\n",
        "- output.csv: containing sizes for all detected organoids\n",
        "- output_summary.csv: containing mean organoid size, std of the organoid size and number of detected orgaoinds for each well and each timepoint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcPDIgjH0AJM",
        "colab_type": "code",
        "outputId": "fbbecf3d-3df7-4a41-b6e8-d5dc6734f159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "# Recreate imagelist in case cells are run interactive\n",
        "exclude_strings = ['_detected', '_processed']\n",
        "imagelist = [i for i in Path(folder_path).glob('**/*.jpg') if not any(x in str(i) for x in exclude_strings)]\n",
        "             \n",
        "            #  '_detected' not in str(i) and if '_processed' not in str(i)]\n",
        "\n",
        "for i, IMAGE_PATH in enumerate(imagelist):\n",
        "  # print(, end='\\r')\n",
        "  print('\\r', f'analysing image: {i+1} of {len(imagelist)}', end='')\n",
        "  # load image\n",
        "  image = read_image_bgr(IMAGE_PATH)\n",
        "\n",
        "  # copy to draw on\n",
        "  draw = image.copy()\n",
        "  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # preprocess image for network\n",
        "  image = adjust_contrast(image,contrast)\n",
        "  image = preprocess_image(image)\n",
        "  image, scale = resize_image(image, min_side=min_side, max_side=2048)\n",
        "\n",
        "  # process image\n",
        "  boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
        "\n",
        "  # correct for image scale\n",
        "  boxes /= scale\n",
        "\n",
        "  out = np.empty((0,4), dtype=np.float32)\n",
        "  out_scores = []\n",
        "\n",
        "  # visualize detections\n",
        "  for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
        "      # scores are sorted so we can break\n",
        "      if score < threshold:\n",
        "          break\n",
        "      out = np.append(out, box.reshape(1,4), axis=0)\n",
        "      out_scores.append(score)\n",
        "\n",
        "      b = box.astype(int)\n",
        "      draw_box(draw, b, color=(255, 0, 255))\n",
        "\n",
        "  output = pd.DataFrame(out,columns=['x1', 'y1', 'x2', 'y2'], dtype=np.int16)\n",
        "  output['score'] = out_scores\n",
        "  output['Diameter 1 (Pixels)'] = output['x2'] - output['x1']\n",
        "  output['Diameter 2 (Pixels)'] = output['y2'] - output['y1']\n",
        "  output.to_csv(str(IMAGE_PATH) + '.csv', index=False)\n",
        "  plt.imsave(str(IMAGE_PATH) + '_detected.png', draw)\n",
        "\n",
        "  # Renaming image to _processed\n",
        "\n",
        "  target_filename = str(IMAGE_PATH) + '_processed.jpg'\n",
        "  shutil.copyfile(str(IMAGE_PATH), target_filename)\n",
        "  os.remove(str(IMAGE_PATH))\n",
        "\n",
        "\n",
        "print('\\n done')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " done\n",
            "Saving output\n",
            "Output is saved\n",
            "Saving combined output csv with all data\n",
            "Output is saved\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}